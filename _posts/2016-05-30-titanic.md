---
title: "Predicting Survival on the Titanic"
excerpt: "This post completes a predictive analysis of who were likely to survive on the Titanic"
header:
  overlay_image: titanic5.jpg
  overlay_filter: 0.4
  caption: ""
  cta_label: " "
categories:
  - data science
tags:
  - Titanic
  - Kuggle competition
  - imputation
  - binary classification 
  - nested cross-validation
author: "Marina Drus"
date: "15 October 2016"
---

{% include base_path %}

### Introduction

[RMS Titanic]9https://en.wikipedia.org/wiki/RMS_Titanic) was a British passenger liner that sank on April 15, 1912 on his way to New York. It perhaps was the most infamous shipwreck in the world history. The Titanic sank after colluding with an iceberg killing 1502 out of 2224 people, including passengers and crew. The Titanic data set obtained from [Kaggle](https://www.kaggle.com/c/titanic/data) contains data for only 891 passengers of the Titanic who either survived or died during the disaster. This is a basic Kaggle data set that can be approached with a challenge and creativity. The data set contains the information about age, sex, passengers class, family on-board, ticket number, ticket price, where passengers boarded the ship, and cabins location. The ultimate goal here was to get the highest possible accuracy score and achieve ranking of top 10% in Kaggle competition.

### Analysis Overview and Strategy

To approach the problem of determining who survived or died in the Titanic accident, I broke the analysis into several parts, including an initial exploratory analysis. In the initial explanatory stage, I wanted to detect any possible interactions for defining my statistical model. When features [interact](https://en.wikipedia.org/wiki/Interaction_(statistics)), the effect of one independent variable depends on the level of the other independent variables.

For example, intuitively it makes sense to assume that more females survived on the Titanic than males. However, it also makes sense to assume that more females who traveled in 1st class vs. females who traveled in 3rd class survived. That is, if females of 1st class were more like to survive than females of 3rd class, there is a possible interaction. Another possible interaction is between age and class and so on. Thus, my first goal was to explore all the possible interactions. 

My second goal was to address missing data for the variable Age. About a 20% of the total number of observations for Age are missing values, which would leave me with only 712 data points and decrease predictive accuracy of the model. This problem could be addressed by using an advanced imputation method. 

Since the data set contain more data on people who perished vs. survived, my third goal was to combat the imbalanced classes using a synthetic minority over-sampling technique. Finally, nested cross-validation was applied to measure and evaluate the predictive performance of the model.

### Explanatory Data Analysis 

The correlational matrix below explores the relationship between features. Although, correlational matrix is not specifically informative to explore relationship between categorical and continuous features, some minor trends can be detected. 


![Correlational Matrix]({{ site.url }}{{ site.baseurl }}/images/pic3_1.png){: .align-center} 


As seen on the matrix, the relationship between features varies from small to moderate. No all independent variables have significant relationships with the binary outcome Survive, but as I mentioned earlier correlational matrix is not a perfectly informative of a significant relationship between categorical and continuous features. 

A set of histogram of continuous features below indicates that normal distribution of Age was slightly skewed towards younger people. The number of younger people (age of 0 to 20) in the data set exceeded the number of elder people (age of 50 and up). 


![Histograms]({{ site.url }}{{ site.baseurl }}/images/pic3_2.png){: .align-center} 


More passengers traveled alone and had neither children, nor parents, nor other family members accompanied them. Most passengers(approximately 70%) paid for their fare 50 pounds or less.

A fist possible interaction between Age and Sex is explored next. Note that each dot on the swarmplot represents a passenger. It looks like age played a significant role in survival of young boys. Age did not seem to play any role in survival of females -- females across all ages were more likely to survive on the Titanic.


![Age and Sex Interaction]({{ site.url }}{{ site.baseurl }}/images/pic3_3.png){: .align-center} 


Second possible interaction was explored between Age and Class. 


![Age and Class Interaction]({{ site.url }}{{ site.baseurl }}/images/pic3_4.png){: .align-center} 


It is obvious from the swarmplot that the passengers of 1st class vs. 2nd and 3rd classes were more likely to survive on the Titanic. However, passengers of infant age were more likely to survive regardless of their class. 

The next swarmplot looks into interactive relationship between fare and a port of embarkation. In general passengers who embarked in Queenstown were less likely to survive. Also, it seems that proportion wise, passengers who embarked in Cherbourg were more likely to survive. 


![Fare and Embarked]({{ site.url }}{{ site.baseurl }}/images/pic3_5.png){: .align-center}


The richest passengers on the ship, who paid the highest fare (over $500) and who embarked in Cherbourg, survived as well. For very rich passengers gender did not matter whether they would survive or not.

Although the three richest passengers on the Titanic survived regardless of their gender, cost of the ticket played a significant role in whether females survived or not. 

 
![Fare and Sex]({{ site.url }}{{ site.baseurl }}/images/pic3_6.png){: .align-center}


More females who paid high fare vs. low fare survived. That was not the case for males. Males were less likely to survive regardless of the fare they paid. Well, it definitely did not pay off to be a male on the Titanic unless he was a super rich male. 

The bar plots below explore  the interaction between gender and class. It replicates the findings from the Fare by Sex interaction, but it is another alternative interaction to explore. Females of 1st and 2nd class were more likely to survive, but that was not a case for males. Males were less likely to survive regardless of their class. 


![Gender and Class]({{ site.url }}{{ site.baseurl }}/images/pic3_7.png){: .align-center}


### Imputation, Synthetic Minority Over-Sampling Technique, and Final Model

Before conducting model selection and evaluation, several imputations were employed to impute missing data for Age. Imputation techniques are mostly suitable for continuous variables. I don’t think I have ever seen any imputation technique that impute categorical data, but I am sure in the age of data science everything is possible. 

I used several advanced imputation techniques to impute the continuous variable Age. I am a very strong opponent of using mean or median imputation to impute data. It is very bad practice in general as it leads to distortion of relationship between variables by pulling estimates of the correlation towards zero. Thus, I applied 4 advanced techniques to impute the Titanic data: 1) KNN, 2) Convex Optimization, 3) Spectral Regulation Algorithm, and 4) Multiple Imputations by Chain Equations or MICE. 

To compare across the imputation algorithms, I [used root-mean-square error (RMSE)](https://en.wikipedia.org/wiki/Root-mean-square_deviation), replicating work by Schmitt, Mandel, and Guedj (2015). This method, however, did not bring me any success as I found no variations in imputation techniques detected by RMSE. Thus, I performed a model comparison (for review see Schmitt, Mandel, & Guedj, 2015) by comparing accuracy scores of various algorithms. See python codes and outputs here. I finally chose the KNN imputation technique as it gave me the highest accuracy scores across the algorithms. 

Further, I compared the accuracy scores across various algorithms (Decision Tree, Logistic Regression, Bagging DT, Random Forest, Extra Trees, Ada Boost, Gradient Boosting, Bernoulli NB, and KNN ) and various statistical models (models with/without various interactions) for the imputed data set and for the original data set. My final choice was the statistical model with Fare-by-Sex interaction with KNN imputation and the Gradient Boosting Algorithm.

Finally, I performed a synthetic minority over-sampling technique, Random Over Sampler. I chose this one because, from my experience, it tends to yield higher model accuracy scores. To evaluate and tune my model, I conducted a [nested cross-validation](https://chrisalbon.com/machine-learning/nested_cross_validation.html). Nested cross-validation is the best way to evaluate a model when a data set is small. This technique allows to avoid a model's overfitting (Cawley, & Talbot, 2010). 

After performing all these techniques, I obtained 99.08% accuracy score on my training set, 98.64% on my test set, and 98.91% accuracy on my the complete data set. Below are the confusion matrices for training, test, and complete data sets.


![Confusion Matrix]({{ site.url }}{{ site.baseurl }}/images/pic3_8.png){: .align-center}


These techniques also helped me to yeild very high AUC scores. 


![AUC Scores]({{ site.url }}{{ site.baseurl }}/images/pic3_9.png){: .align-center}


### Conclusion

Achieving 98.64% accuracy on 40% of the Titanic test data is quite impressive. This would be a top 2% score on the Kaggle board. I don’t think I expected these results, and I am pleasantly surprised. This high score was achieved using an imputation technique, a synthetic minority over-sampling technique (Random Over Sampler), and statistical modeling techniques. 

{% capture notice-2 %}
#### REFERENCES

Acuna, Edgar, and Caroline Rodriguez. "The treatment of missing values and its effect on classifier accuracy." Classification, clustering, and data mining applications (2004): 639-647.

Azur, Melissa J., et al. "Multiple imputation by chained equations: what is it and how does it work?." International journal of  methods in psychiatric research 20.1 (2011): 40-49.

Candes, Emmanuel, and Benjamin Recht. "Exact matrix completion via convex optimization." Communications of the ACM 55.6 (2012): 111-119

Cawley, Gavin C., and Nicola LC Talbot. "On over-fitting in model selection and subsequent selection bias in performance evaluation." Journal of Machine Learning Research 11.Jul (2010): 2079-2107.

Mazumder, Rahul, Trevor Hastie, and Robert Tibshirani. "Spectral regularization algorithms for learning large incomplete matrices." Journal of machine learning research 11.Aug (2010): 2287-2322.

Schmitt, Peter, Jonas Mandel, and Mickael Guedj. "A comparison of six methods for missing data imputation." Journal of Biometrics & Biostatistics 6.1 (2015): 1.
{% endcapture %}

<div class="notice">
  {{ notice-2 | markdownify }}
</div>
















